Metadata-Version: 2.4
Name: tinyllava
Version: 1.0.0
Summary: A Framework of Small-scale Large Multimodal Models.
Project-URL: Homepage, https://github.com/X-PLUG/mPLUG-DocOwl/blob/main/TinyChart
Project-URL: Bug Tracker, https://github.com/X-PLUG/mPLUG-DocOwl/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: torch==2.0.1
Requires-Dist: torchvision==0.15.2
Requires-Dist: tiktoken
Requires-Dist: transformers==4.37.2
Requires-Dist: tokenizers==0.15.1
Requires-Dist: sentencepiece==0.1.99
Requires-Dist: shortuuid
Requires-Dist: accelerate==0.21.0
Requires-Dist: peft==0.4.0
Requires-Dist: bitsandbytes==0.41.0
Requires-Dist: pydantic<2,>=1
Requires-Dist: markdown2[all]
Requires-Dist: numpy
Requires-Dist: scikit-learn==1.2.2
Requires-Dist: gradio==3.35.2
Requires-Dist: gradio_client==0.2.9
Requires-Dist: requests
Requires-Dist: httpx==0.24.0
Requires-Dist: uvicorn
Requires-Dist: fastapi
Requires-Dist: einops==0.6.1
Requires-Dist: einops-exts==0.0.4
Requires-Dist: timm==0.6.13
Provides-Extra: train
Requires-Dist: deepspeed==0.9.5; extra == "train"
Requires-Dist: ninja; extra == "train"
Requires-Dist: wandb; extra == "train"

# TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning

<div align="center">
Liang Zhang*, Anwen Hu*, Haiyang Xu, Ming Yan, Yichen Xu, Qin Jin‚Ä†, Ji Zhang, Fei Huang

\* Equal Contribution 
‚Ä† Corresponding Author


</div>


<div align="center">
<a href="https://arxiv.org/abs/2404.16635"><img src="assets/Paper-Arxiv-orange.svg" ></a>
</div>

<hr>
<div align="center">
<img src="assets/perform_and_speed.png" alt="image" width="100%" height="auto">
</div>
</p>

## Spotlights

* Support chart question answering with both simple direct answers and step-by-step Python programs.
* Support chart-to-table extraction, chart summary generation, and chart redrawing.
* Opensource:
    - ‚úÖ Model: TinyChart
    - ‚úÖ Inference code.
    - ‚úÖ Code of launching a local demo.
    - ‚úÖ Online demo on HuggingFace.
    - ‚úÖ Evaluation code.
    - ‚úÖ Training data and code.

## Examples
<div align="center">
<img src="assets/cases.png" alt="image" width="100%" height="auto">
</div>

## Online Demo
[ü§ó Huggingface Space](https://huggingface.co/spaces/mPLUG/TinyChart-3B)

## Models
### Model Card
|  Model   | Download Link  |
|  ----  | ----  |
| TinyChart@768  | ü§ó [mPLUG/TinyChart-3B-768](https://huggingface.co/mPLUG/TinyChart-3B-768) <br> ü§ñ [iic/TinyChart-3B-768](https://modelscope.cn/models/iic/TinyChart-3B-768)|
| TinyChart@768-SigLIP | ü§ó [mPLUG/TinyChart-3B-768-siglip](https://huggingface.co/mPLUG/TinyChart-3B-768-siglip) <br> ü§ñ [iic/TinyChart-3B-768-siglip](https://modelscope.cn/models/iic/TinyChart-3B-768-siglip)

Note that to use TinyChart@768, you should load the vision transformer with token merging from TinyChart@768-SigLIP. If you download the model into local directory, you should change `mm_vision_tower` in `config.json` of `TinyChart-3B-768` to make sure it can find `TinyChart-3B-768-siglip`.

### Quick Start
You can load the model with the following code.
```
from tinychart.model.builder import load_pretrained_model

model_path = "mPLUG/TinyChart-3B-768"
tokenizer, model, image_processor, context_len = load_pretrained_model(
    model_path, 
    model_base=None,
    model_name=get_model_name_from_path(model_path),
    device="cuda"
)
```

### Model Inference
We provide an example script to perform inference in [`inference.ipynb`](inference.ipynb).

## Model Training & Evaluation
### Data preparation
The training and evaluation data of TinyChart is released at ü§ó [mPLUG/TinyChartData](https://huggingface.co/datasets/mPLUG/TinyChartData). Samples with id contains `tempatepot` and `gptpot` are the two subsets of the proposed ChartQA-PoT dataset. To perform training and evaluation, you should download and organize the `data` directory as follows:
```
data
‚îú‚îÄ‚îÄ tinychart_images
‚îú‚îÄ‚îÄ train.json
‚îú‚îÄ‚îÄ test.json

```
Then download [`bczhou/TinyLLaVA-3.1B-SigLIP`](https://huggingface.co/bczhou/TinyLLaVA-3.1B-SigLIP) into `pretrained_models`, and run this script to add arguments about token merging. Note that this script will change the `config.json` of the model **inplace**, please backup in advance.
```
python scripts/vit_add_tome.py --path pretrained_models/TinyLLaVA-3.1B-SigLIP
```

After that, run the following scripts to start training. It will automatically load the last checkpoint to perform evaluation.
```
bash scripts/train.sh
```

## Local Demo
You can run a local demo with the following scrit:
```
python app.py --model-path <your_model_path>
```

## Citation
If you find this work useful, consider giving this repository a star ‚≠êÔ∏è and citing üìù our paper as follows:
```
@misc{zhang2024tinychart,
    title={TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning}, 
    author={Liang Zhang and Anwen Hu and Haiyang Xu and Ming Yan and Yichen Xu and Qin Jin and Ji Zhang and Fei Huang},
    year={2024},
    eprint={2404.16635},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

## Acknowledgement
The code is based on the [TinyLLaVA](https://github.com/DLCV-BUAA/TinyLLaVABench), [LLaVA](https://github.com/haotian-liu/LLaVA), and [ToMe](https://github.com/facebookresearch/ToMe). Thanks for these great works and open-sourcing!
